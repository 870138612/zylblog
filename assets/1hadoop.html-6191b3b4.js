import{_ as e}from"./plugin-vue_export-helper-c27b6911.js";import{o as a,c as i,f as l}from"./app-5fd1b6fe.js";const r={},d=l('<h3 id="mapreduce-是什么" tabindex="-1"><a class="header-anchor" href="#mapreduce-是什么" aria-hidden="true">#</a> MapReduce 是什么？</h3><ul><li>MapReduce 是一个并行程序设计模型与方法（Programming Model &amp; Methodology）。它提供了一种简便的并行程序设计方法，用 Map 和 Reduce 两个函数编程实现基本的并行计算任务，提供了抽象的操作和并行编程接口，以简单方便地完成大规模数据的编程和计算处理。</li></ul><h3 id="mapreduce-详细的工作流程" tabindex="-1"><a class="header-anchor" href="#mapreduce-详细的工作流程" aria-hidden="true">#</a> MapReduce 详细的工作流程</h3><ol><li>在客户端执行 submit() 方法之前，先会获取待读取文件的信息。</li><li>将 job 提交给 yarn，这时候会带上三个信息过去。（文件的切片信息，jar，job.xml)</li><li>yarn 会通过切片信息去计算需要启动的 maptask 数量，然后启动 maptask。</li><li>maptask 会调用 InPutFormat() 方法去 HDFS 上面读取文件，InputFormat() 会再去调用 RecordRead() 方法将数据以行首字母的偏移量作为 key，一行数据作为 value 传给 mapper() 方法。</li><li>mapper 方法做完处理之后，将数据转移到分区方法中，对数据进行标注之后，发送到环形缓冲区。</li><li>环形缓冲区的大小默认是 100M，达到 80% 将会发生溢写。</li><li>在溢写之前会做一个排序动作，排序的规则是按照 key 进行字典排序，排序的手段是快速排序。</li><li>溢写会产生出大量的溢写文件，会再次调用 merge() 方法，使用归并排序，默认十个溢写文件构成一个大文件。</li><li>也可以对溢写文件进行一个 localReduce，也就是 combiner 的操作，但前提是 combiner 的结果不能对最终结果产生影响。</li><li>等待所有的 maptask 执行完毕之后，会启动一定数量的 reducetask。</li><li>reducetask 会在 map 端拉取数据，数据会先加载到内存中，内存不够会写入磁盘，等待所有的数据拉去完毕之后，将这些数据再次进行一次归并操作。</li><li>归并之后的文件会再进行一次分组操作，然后将数据以组为单位发送给 reduce() 方法。</li><li>reduce() 方法会做一些逻辑判断，最终调用 OutputFormat() 方法，OutputFormat() 会调用 RecordWrite() 方法将数据以 KV 的形式写出到 HDFS 上。</li></ol><h3 id="hdfs-分布式存储工作机制" tabindex="-1"><a class="header-anchor" href="#hdfs-分布式存储工作机制" aria-hidden="true">#</a> HDFS 分布式存储工作机制</h3><ul><li>HDFS 是一个文件存储系统，他的 meta 信息以及目录结构是存储在 NameNode 中，文件是以 block 的形式存储在 DataNode 中，通过与 NameNode 交互，可以实现读写操作。</li><li>读操作 <ul><li>客户端先带着读取路径向 NameNode 发送读取请求。</li><li>NameNode 接收到读取请求之后，判断是否有权限，读取文件是否存在等，如果都通过，则发送给客户端部分或者全部的 DataNode 节点位置。</li><li>客户端得到文件位置之后，调用 read() 方法，去读取数据。</li><li>在读取之后先进行一个 checksum 的操作，去判断以下校验和是否正确，正确则读取，否则则去下一个存放 block 块的 DataNode 节点上读取。</li><li>读取完成 DataNode 这次发送过来的所有 block 块之后，再去询问是否有 block 块，如果有则直接读取，没有则调用 close() 方法，将读取的所有文件合并成一个大文件。</li></ul></li><li>写操作 <ul><li>客户端带着路径向 NameNode 发送写请求。</li><li>NameNode 会判断是否有权限，写入路径的父路径是否存在，如果都通过则将请求返回给客户端。</li><li>客户端会将文件进行切分，然后上传 block。</li><li>NameNode 会根据 DataNode 的存储空间还有机架感知原理等返回该 block 块要存储的 DataNode 的位置 ABC。</li><li>客户端会去 ABC 三个 DataNode 节点上建立 pipeline A-B B-C 然后 C 建立完成之后会将结果返回给 B ，B 返回给 A，A 返回给客户端。</li><li>开始往 A 写入，一次进行流水线复制。</li><li>写入完成之后再去依次写入其他 block 块。</li><li>都写入完成之后则将写入完成的信息返回给 NameNode。</li><li>NameNode 存储该文件的各个 block 块的元数据信息。</li></ul></li></ul><h3 id="yarn-资源调度工作机制" tabindex="-1"><a class="header-anchor" href="#yarn-资源调度工作机制" aria-hidden="true">#</a> yarn 资源调度工作机制</h3><ol><li>客户端向 ResourceManager 提交作业。</li><li>ResourceManager 会去 NodeManager 中开启一个 container 来运行 ApplicationMaster。</li><li>ApplicationMaster 向 ResourceManager 注册自己。</li><li>申请相应数量的 container 来运行 task 任务。</li><li>container 会先进行初始化操作，初始化完成 ApplicationMaster 会通知对应的 NodeManager 开启 container。</li><li>NodeManager 开启 container。</li><li>container 在运行期间会向 ApplicationMaster 汇报自己的进度，状态信息，并与其保持心跳。</li><li>等待应用执行完毕，ApplicationMaster 向 ResourceManager 注销自己，并允许回收自己的资源。</li></ol><h3 id="hadoop-的组成" tabindex="-1"><a class="header-anchor" href="#hadoop-的组成" aria-hidden="true">#</a> Hadoop 的组成</h3><ol><li>HDFS <ul><li>管理者 NameNode 文件元数据存储</li><li>工作者 DataNode 存储具体数据</li><li>辅助管理者 SecondaryNameNode 辅助 NameNode 合并文件</li></ul></li><li>MapReduce 海量数据分析计算框架</li><li>Yarn <ul><li>管理者 ResourceManager 整个集群的资源管理者</li><li>工作者 NodeManager 单个节点的管理者</li></ul></li></ol><h3 id="mapperreduce-的-shuffle-过程" tabindex="-1"><a class="header-anchor" href="#mapperreduce-的-shuffle-过程" aria-hidden="true">#</a> MapperReduce 的 Shuffle 过程</h3><ul><li>Shuffle 过程就是 mapper 之后，reduce 之前做的事情。</li><li>mapper() 方法之后将数据发送到分区中，给数据标记好分区，将数据发送到环形缓冲区。</li><li>环形缓冲区的大小默认是 100M，达到 80% 会进行溢写。</li><li>溢写之前会进行排序，排序的规则是字典排序，使用快速排序。</li><li>溢写产生很多溢写文件，默认达到 10 个会进行合并，合并时采用归并排序。</li><li>也可以进行 container 局部聚合的操作，前提是局部聚合的结果不会对最终的结果产生影响。</li><li>等到所有 maptask 运行完毕，启动一定数量的 reducetask，告知 reducetask 读取数据的范围（也就是分区）。</li><li>reducetask 发送拉去线程，去 map 端拉去数据，数据线存储到内存中，内存放不下就放入磁盘中，数据拉去完毕之后进行归并排序。</li><li>最后对数据进行分组，以组为单位发送到 reduce() 方法中。</li></ul><h3 id="hadoop-的垃圾回收机制" tabindex="-1"><a class="header-anchor" href="#hadoop-的垃圾回收机制" aria-hidden="true">#</a> Hadoop 的垃圾回收机制</h3><ul><li>HDFS 的回收站必须是开启的，一般设置生存时间为 7 天，超过之后就会真正删除。</li><li>Hadoop NameNode 配置的垃圾回收器是 G1。</li></ul><h3 id="mapreduce-为什么分成两个部分-而不是直接-map-或者-reduce" tabindex="-1"><a class="header-anchor" href="#mapreduce-为什么分成两个部分-而不是直接-map-或者-reduce" aria-hidden="true">#</a> mapreduce 为什么分成两个部分，而不是直接 map 或者 reduce？</h3><ul><li>两个不是是为了实现分布式计算，提高计算效率。</li><li>很多情况下是需要对整个数据进行计算，单独分成小文件虽然能提高计算效率，但是无法完成实际需求，没有实际意义。</li><li>添加 reduce 阶段之后，负责将多个部分计算的结果进行汇总处理，使得满足实际需求。</li></ul><h3 id="map-任务和-reduce-任务在哪里运行" tabindex="-1"><a class="header-anchor" href="#map-任务和-reduce-任务在哪里运行" aria-hidden="true">#</a> map 任务和 reduce 任务在哪里运行？</h3><ul><li>将 MR 程序送入到 Yarn 上。</li><li>通过 container 运行。</li></ul><h3 id="hadoop-切片原则" tabindex="-1"><a class="header-anchor" href="#hadoop-切片原则" aria-hidden="true">#</a> Hadoop 切片原则</h3><ul><li>按照块大小进行切分，默认是 128M。</li></ul><h3 id="yarn-的核心组件和调度器" tabindex="-1"><a class="header-anchor" href="#yarn-的核心组件和调度器" aria-hidden="true">#</a> Yarn 的核心组件和调度器</h3><ul><li>三个核心组件 <ul><li>ResourceManager：负责整个集群的资源分配。</li><li>NodeManager：每个节点上的资源管理器。</li><li>ApplicationMaster：单个应用程序的管理者。</li></ul></li><li>三种调度器 <ul><li>FIFO：先提交的任务就先分配资源。</li><li>CapcityScheduler：以队列为单位划分资源。会给每个队列配置最小保证资源和最大可用资源。最小配置资源保证队列一定能拿到这么多资源，有空闲可共享给其他队列使用；最大可用资源限制队列最多能使用的资源，防止过度消耗。</li><li>FairScheduler：Fair Scheduler 也是一个多用户调度器，它同样添加了多层级别的资源限制条件以更好地让多用户共享一个 Hadoop 集群，比如队列资源限制、用户应用程序数目限制等。在 Fair 调度器中，我们不需要预先占用一定的系统资源，Fair 调度器会为所有运行的 job 动态的调整系统资源。</li></ul></li></ul><h3 id="fsimage-和-editlog" tabindex="-1"><a class="header-anchor" href="#fsimage-和-editlog" aria-hidden="true">#</a> fsimage 和 editlog</h3><ul><li>fsimage 保存了最新的元数据检查点，在 HDFS 启动时加载 fsimage 的信息，包含了整个 HDFS 文件系统的所有目录和文件的信息。 对于文件来说包括了数据块描述信息、修改时间、访问时间等；对于目录来说包括修改时间、访问权限控制信息（目录所属用户，所在组）等。</li><li>editlog 主要是在 NameNode 已经启动情况下对 HDFS 进行的各种更新操作进行记录，HDFS 客户端执行所有的写操作都会被记录到 editlog 中。</li></ul>',24),o=[d];function c(t,u){return a(),i("div",null,o)}const p=e(r,[["render",c],["__file","1hadoop.html.vue"]]);export{p as default};
