import{_ as e}from"./plugin-vue_export-helper-c27b6911.js";import{o as a,c as i,e as l}from"./app-2da47895.js";const r={},o=l('<h3 id="mapperreduce-详细的工作流程" tabindex="-1"><a class="header-anchor" href="#mapperreduce-详细的工作流程" aria-hidden="true">#</a> MapperReduce 详细的工作流程</h3><ol><li>在客户端执行 submit() 方法之前，先会获取待读取文件的信息。</li><li>将 job 提交给 yarn，这时候会带上三个信息过去。（文件的切片信息，jar，job.xml)</li><li>yarn 会通过切片信息去计算需要启动的 maptask 数量，然后启动 maptask。</li><li>maptask 会调用 InPutFormat() 方法去 HDFS 上面读取文件，InputFormat() 会再去调用 RecordRead() 方法将数据以行首字母的偏移量作为 key，一行数据作为 value 传给 mapper() 方法。</li><li>mapper 方法做完处理之后，将数据转移到分区方法中，对数据进行标注之后，发送到环形缓冲区。</li><li>环形缓冲区的大小默认是 100M，达到 80% 将会发生溢写。</li><li>在溢写之前会做一个排序动作，排序的规则是按照 key 进行字典排序，排序的手段是快速排序。</li><li>溢写会产生出大量的溢写文件，会再次调用 merge() 方法，使用归并排序，默认十个溢写文件构成一个大文件。</li><li>也可以对溢写文件进行一个 localReduce，也就是 combiner 的操作，但前提是 combiner 的结果不能对最终结果产生影响。</li><li>等待所有的 maptask 执行完毕之后，会启动一定数量的 reducetask。</li><li>reducetask 会在 map 端拉取数据，数据会先加载到内存中，内存不够会写入磁盘，等待所有的数据拉去完毕之后，将这些数据再次进行一次归并操作。</li><li>归并之后的文件会再进行一次分组操作，然后将数据以组为单位发送给 reduce() 方法。</li><li>reduce() 方法会做一些逻辑判断，最终调用 OutputFormat() 方法，OutputFormat() 会调用 RecordWrite() 方法将数据以 KV 的形式写出到 HDFS 上。</li></ol><h3 id="hdfs-分布式存储工作机制" tabindex="-1"><a class="header-anchor" href="#hdfs-分布式存储工作机制" aria-hidden="true">#</a> HDFS 分布式存储工作机制</h3><ul><li>HDFS 是一个文件存储系统，他的 meta 信息以及目录结构是存储在 NameNode 中，文件是以 block 的形式存储在 DataNode 中，通过与 NameNode 交互，可以实现读写操作。</li><li>读操作 <ul><li>客户端先带着读取路径向 NameNode 发送读取请求。</li><li>NameNode 接收到读取请求之后，判断是否有权限，读取文件是否存在等，如果都通过，则发送给客户端部分或者全部的 DataNode 节点位置。</li><li>客户端得到文件位置之后，调用 read() 方法，去读取数据。</li><li>在读取之后先进行一个 checksum 的操作，去判断以下校验和是否正确，正确则读取，否则则去下一个存放 block 块的 DataNode 节点上读取。</li><li>读取完成 DataNode 这次发送过来的所有 block 块之后，再去询问是否有 block 块，如果有则直接读取，没有则调用 close() 方法，将读取的所有文件合并成一个大文件。</li></ul></li><li>写操作 <ul><li>客户端带着路径向 NameNode 发送写请求。</li><li>NameNode 会判断是否有权限，写入路径的父路径是否存在，如果都通过则将请求返回给客户端。</li><li>客户端会将文件进行切分，然后上传 block。</li><li>NameNode 会根据 DataNode 的存储空间还有机架感知原理等返回该 block 块要存储的 DataNode 的位置 ABC。</li><li>客户端会去 ABC 三个 DataNode 节点上建立 pipeline A-B B-C 然后 C 建立完成之后会将结果返回给 B ，B 返回给 A，A 返回给客户端。</li><li>开始往 A 写入，一次进行流水线复制。</li><li>写入完成之后再去依次写入其他 block 块。</li><li>都写入完成之后则将写入完成的信息返回给 NameNode。</li><li>NameNode 存储该文件的各个 block 块的原数据信息。</li></ul></li></ul><h3 id="yarn-资源调度工作机制" tabindex="-1"><a class="header-anchor" href="#yarn-资源调度工作机制" aria-hidden="true">#</a> yarn 资源调度工作机制</h3><ol><li>客户端向 ResourceManager 提交作业。</li><li>ResourceManager 会去 NodeManager 中开启一个 container 来运行 ApplicationMaster。</li><li>ApplicationMaster 向 ResourceManager 注册自己。</li><li>申请相应数量的 container 来运行 task 任务。</li><li>container 会先进行初始化操作，初始化完成 ApplicationMaster 会通知对应的 NodeManager 开启 container。</li><li>NodeManager 开启 container。</li><li>container 在运行期间会向 ApplicationMaster 汇报自己的进度，状态信息，并与其保持心跳。</li><li>等待应用执行完毕，ApplicationMaster 向 ResourceManager 注销自己，并允许回收自己的资源。</li></ol><h3 id="hadoop-的组成" tabindex="-1"><a class="header-anchor" href="#hadoop-的组成" aria-hidden="true">#</a> Hadoop 的组成</h3><ol><li>HDFS <ul><li>管理者 NameNode 文件元数据存储</li><li>工作者 DataNode 存储具体数据</li><li>辅助管理者 SecondaryNameNode 辅助 NameNode 合并文件</li></ul></li><li>MapReduce 海量数据分析计算框架</li><li>Yarn <ul><li>管理者 ResourceManager 整个集群的资源管理者</li><li>工作者 NodeManager 单个节点的管理者</li></ul></li></ol><h3 id="mapperreduce-的-shuffle-过程" tabindex="-1"><a class="header-anchor" href="#mapperreduce-的-shuffle-过程" aria-hidden="true">#</a> MapperReduce 的 Shuffle 过程</h3><ul><li>Shuffle 过程就是 mapper 之后，reduce 之前做的事情。</li><li>mapper() 方法之后将数据发送到分区中，给数据标记好分区，将数据发送到环形缓冲区。</li><li>环形缓冲区的大小默认是 100M，达到 80% 会进行溢写。</li><li>溢写之前会进行排序，排序的规则是字典排序，使用快速排序。</li><li>溢写产生很多溢写文件，默认达到 10 个会进行合并，合并时采用归并排序。</li><li>也可以进行 container 局部聚合的操作，前提是局部聚合的结果不会对最终的结果产生影响。</li><li>等到所有 maptask 运行完毕，启动一定数量的 reducetask，告知 reducetask 读取数据的范围（也就是分区）。</li><li>reducetask 发送拉去线程，去 map 端拉去数据，数据线存储到内存中，内存放不下就放入磁盘中，数据拉去完毕之后进行归并排序。</li><li>最后对数据进行分组，以组为单位发送到 reduce() 方法中。</li></ul><h3 id="hadoop-的垃圾回收机制" tabindex="-1"><a class="header-anchor" href="#hadoop-的垃圾回收机制" aria-hidden="true">#</a> Hadoop 的垃圾回收机制</h3><ul><li>HDFS 的回收站必须是开启的，一般设置生存时间为 7 天，超过之后就会真正删除。</li><li>Hadoop NameNode 配置的垃圾回收器是 G1。</li></ul><h3 id="" tabindex="-1"><a class="header-anchor" href="#" aria-hidden="true">#</a></h3>',13),d=[o];function t(c,n){return a(),i("div",null,d)}const p=e(r,[["render",t],["__file","1hadoop.html.vue"]]);export{p as default};
