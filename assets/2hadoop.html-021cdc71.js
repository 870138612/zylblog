const e=JSON.parse('{"key":"v-3927ecf4","path":"/note/2hadoop.html","title":"Hadoop知识点总结","lang":"zh-CN","frontmatter":{"title":"Hadoop知识点总结","icon":"biji1","date":"2023-09-19T00:00:00.000Z","star":1,"category":["笔记"],"tag":["大数据","Hadoop"]},"headers":[{"level":3,"title":"MapReduce 是什么？","slug":"mapreduce-是什么","link":"#mapreduce-是什么","children":[]},{"level":3,"title":"MapReduce 详细的工作流程","slug":"mapreduce-详细的工作流程","link":"#mapreduce-详细的工作流程","children":[]},{"level":3,"title":"HDFS 分布式存储工作机制","slug":"hdfs-分布式存储工作机制","link":"#hdfs-分布式存储工作机制","children":[]},{"level":3,"title":"yarn 资源调度工作机制","slug":"yarn-资源调度工作机制","link":"#yarn-资源调度工作机制","children":[]},{"level":3,"title":"Hadoop 的组成","slug":"hadoop-的组成","link":"#hadoop-的组成","children":[]},{"level":3,"title":"MapperReduce 的 Shuffle 过程","slug":"mapperreduce-的-shuffle-过程","link":"#mapperreduce-的-shuffle-过程","children":[]},{"level":3,"title":"Hadoop 的垃圾回收机制","slug":"hadoop-的垃圾回收机制","link":"#hadoop-的垃圾回收机制","children":[]},{"level":3,"title":"mapreduce 为什么分成两个部分，而不是直接 map 或者 reduce？","slug":"mapreduce-为什么分成两个部分-而不是直接-map-或者-reduce","link":"#mapreduce-为什么分成两个部分-而不是直接-map-或者-reduce","children":[]},{"level":3,"title":"map 任务和 reduce 任务在哪里运行？","slug":"map-任务和-reduce-任务在哪里运行","link":"#map-任务和-reduce-任务在哪里运行","children":[]},{"level":3,"title":"Hadoop 切片原则","slug":"hadoop-切片原则","link":"#hadoop-切片原则","children":[]},{"level":3,"title":"Yarn 的核心组件和调度器","slug":"yarn-的核心组件和调度器","link":"#yarn-的核心组件和调度器","children":[]},{"level":3,"title":"fsimage 和 editlog","slug":"fsimage-和-editlog","link":"#fsimage-和-editlog","children":[]}],"git":{"createdTime":1702287787000,"updatedTime":1702287787000,"contributors":[{"name":"ZYL1210","email":"870138612@qq.com","commits":1}]},"readingTime":{"minutes":7.31,"words":2192},"filePathRelative":"note/2hadoop.md","localizedDate":"2023年9月19日","excerpt":"<h3> MapReduce 是什么？</h3>\\n<ul>\\n<li>MapReduce 是一个并行程序设计模型与方法（Programming Model &amp; Methodology）。它提供了一种简便的并行程序设计方法，用 Map 和 Reduce 两个函数编程实现基本的并行计算任务，提供了抽象的操作和并行编程接口，以简单方便地完成大规模数据的编程和计算处理。</li>\\n</ul>\\n<h3> MapReduce 详细的工作流程</h3>\\n<ol>\\n<li>在客户端执行 submit() 方法之前，先会获取待读取文件的信息。</li>\\n<li>将 job 提交给 yarn，这时候会带上三个信息过去。（文件的切片信息，jar，job.xml)</li>\\n<li>yarn 会通过切片信息去计算需要启动的 maptask 数量，然后启动 maptask。</li>\\n<li>maptask 会调用 InPutFormat() 方法去 HDFS 上面读取文件，InputFormat() 会再去调用 RecordRead() 方法将数据以行首字母的偏移量作为 key，一行数据作为 value 传给 mapper() 方法。</li>\\n<li>mapper 方法做完处理之后，将数据转移到分区方法中，对数据进行标注之后，发送到环形缓冲区。</li>\\n<li>环形缓冲区的大小默认是 100M，达到 80% 将会发生溢写。</li>\\n<li>在溢写之前会做一个排序动作，排序的规则是按照 key 进行字典排序，排序的手段是快速排序。</li>\\n<li>溢写会产生出大量的溢写文件，会再次调用 merge() 方法，使用归并排序，默认十个溢写文件构成一个大文件。</li>\\n<li>也可以对溢写文件进行一个 localReduce，也就是 combiner 的操作，但前提是 combiner 的结果不能对最终结果产生影响。</li>\\n<li>等待所有的 maptask 执行完毕之后，会启动一定数量的 reducetask。</li>\\n<li>reducetask 会在 map 端拉取数据，数据会先加载到内存中，内存不够会写入磁盘，等待所有的数据拉去完毕之后，将这些数据再次进行一次归并操作。</li>\\n<li>归并之后的文件会再进行一次分组操作，然后将数据以组为单位发送给 reduce() 方法。</li>\\n<li>reduce() 方法会做一些逻辑判断，最终调用 OutputFormat() 方法，OutputFormat() 会调用 RecordWrite() 方法将数据以 KV 的形式写出到 HDFS 上。</li>\\n</ol>"}');export{e as data};
