---
title: Redis基础一
icon: page
category:
  - 数据库
tag:
  - Redis
  - 八股
---

## 基础

### 什么是 Redis？

Redis 是一个基于 C 语言开发的开源数据库（BSD 许可），与传统数据库不同的是 Redis 的数据是存在内存中的（内存数据库），读写速度非常快，被广泛应用于缓存方向。并且，Redis 存储的是 KV 键值对数据。

为了满足不同的业务场景，Redis 内置了多种数据类型实现（比如 `String、Hash、Sorted Set、Bitmap、HyperLogLog、GEO`）。并且，Redis 还支持事务、持久化、Lua 脚本、多种开箱即用的集群方案（Redis Sentinel、Redis Cluster）。

### Redis 为什么这么快？

1. Redis 基于内存，内存的访问速度是磁盘的上千倍；

2. Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用（Redis 线程模式后面会详细介绍到）；

3. Redis 内置了多种优化过后的数据结构实现，性能非常高。

### 说一下 Redis 和 Memcached 的区别和共同点？

**共同点**：

1. 都是基于内存的数据库，一般都用来当做缓存使用。
2. 都有过期策略。
3. 两者的性能都非常高。

**区别**：

1. **支持的数据类型**：Redis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 `List，Set，Zset，Hash` 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
2. **持久化**：Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中。
3. **容灾恢复**：Redis 有灾难恢复机制。 因为可以把缓存中的数据持久化到磁盘上。
4. **内存不足操作**：Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。
5. **集群支持**：Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。
6. **线程数**：Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。（Redis 6.0 针对网络数据的读写引入了多线程）
7. **高级功能**：Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。
8. **过期数据删除**：Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。

### 为什么要用 Redis/为什么要用缓存？

**1、高性能**

假如用户第一次访问数据库中的某些数据，这个过程是比较慢，毕竟是从硬盘中读取的。用户访问的数据属于高频数据并且不会经常改变的话，那么就可以很放心地将该用户访问的数据存在缓存中。

**这样有什么好处呢？** 那就是保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。

**2、高并发**

一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 Redis 的情况，Redis 集群的话会更高）。

> QPS（Query Per Second）：服务器每秒可以执行的查询次数；

由此可见，直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高了系统整体的并发。

## 常见的缓存读写策略

### Cache Aside Pattern（旁路缓存模式）

**Cache Aside Pattern 是平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。**

服务端同时维护 db 和 cache，并且是以 db 的结果为准。

**写（缓存失效）**：

- 先更新 db；
- 然后直接删除 cache。

![image-20230607180554413](/markdown/image-20230607180554413.png) 

**读**：

- 从 cache 中读取数据，读到直接返回；
- cache 中没有取到数据，就从 db 中读取数据返回；
- 再把数据放到 cache 中。

![image-20230607180709994](/markdown/image-20230607180709994.png)

::: info 

**在写数据的过程中，可以先删除 cache ，后更新 db 么？**

不行，因为会造成数据库和缓存的数据不一致问题。

> 请求 1 先把 cache 中的 A 数据删除 -> 请求 2 从 db 中读取数据 -> 请求 1 再把 db 中的 A 数据更新。

**在写数据的过程中，先更新 db，后删除 cache 就没有问题了么？**

理论上来说还是可能会出现数据不一致性的问题，不过概率非常小，因为缓存的写入速度是比数据库的写入速度快很多。

> 请求 1 从 db 读数据 A -> 请求 2 更新 db 中的数据 A（此时缓存中无数据 A ，故不用执行删除缓存操作 ） -> 请求 1 将数据 A 写入 cache（发生在请求2更新数据之前则会出现数据不一致）

:::

**缺点1**：首次请求的数据一定不在 cache 中。

解决办法：将热点数据提前放入 cache 中。

**缺点2**：写操作频繁的话会导致 cache 中数据频繁被删除，影响命中率。

解决办法：

- **数据库和缓存数据强一致性场景**：更新 db 的时候同时更新 cache，不过需要添加一个锁来保证更新 cache 的时候不存在线程安全问题。
- **可以短暂地允许数据库和缓存数据不一致的场景**：更新 db 的时候同样更新 cache，但是给缓存加一个比较短的过期时间，这样就能保证即使数据不一致影响也比较小。

### Read/Write Through Pattern（读写穿透）

Read/Write Through Pattern 中服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 db，从而减轻了应用程序的职责。

**写（Write Through）：**

- 先查 cache，cache 中不存在，直接更新 db。
- cache 中存在，则先更新 cache，然后 cache 服务自己更新 db（**同步更新 cache 和 db**）

![image-20230607181734750](/markdown/image-20230607181734750.png)

**读（Read Through）：**

- 从 cache 中读取数据，读取到就直接返回 。
- 读取不到的话，先从 db 加载，写入到 cache 后返回响应。

![image-20230607181753345](/markdown/image-20230607181753345.png)

Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。

和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不在 cache 的问题，对于热点数据可以提前放入缓存中。

### Write Behind Pattern（异步缓存写入）

Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 db 的读写。

但是，两个又有很大的不同：**Read/Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。**

很明显，这种方式对数据一致性带来了更大的挑战，比如 cache 数据可能还没异步更新 db 的话，cache 服务可能就就挂掉了。

这种策略在平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制都用到了这种策略。

Write Behind Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。

## Redis 应用

### Redis 除了做缓存，还能做什么？

**分布式锁**：通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，都是基于 Redisson 来实现分布式锁。（秒杀下更新数据库时使用分布式锁）

☀️详见[分布式锁](http://ylzhong.top/database/2redis/2lock.html)

**限流**：一般是通过 Redis + Lua 脚本的方式来实现限流。（秒杀下一人一单占位使用Lua脚本）

**消息队列**：Redis 自带的 `List` 数据结构可以作为一个简单的队列使用。Redis 5.0 中增加的 `Stream` 类型的数据结构更加适合用来做消息队列。它比较类似于 Kafka，有主题和消费组的概念，支持消息持久化以及 ACK 机制。（快速创建秒杀单之后写回数据库使用消息队列）

> Redis 2.0 之前，如果想要使用 Redis 来做消息队列的话，只能通过 `List` 来实现，`List` 实现消息队列功能太简单，像消息确认机制等功能还需要自己实现，最要命的是没有广播机制，消息也只能被消费一次。
>
> Redis 2.0 引入了发布订阅 (pub/sub) 功能，解决了 List 实现消息队列没有广播机制的问题。Redis 5.0 新增加的一个数据结构 `Stream` 来做消息队列。
>
> `Stream` 支持：
>
> - 发布 / 订阅模式
> - 按照消费者组进行消费
> - 消息持久化（RDB 和 AOF）

**复杂业务场景**：通过 Redis 以及 Redis 扩展（比如 Redisson）提供的数据结构，可以很方便地完成很多复杂的业务场景比如通过 `Bitmap` 统计活跃用户、通过 `Sorted Set` 维护排行榜。

## Redis 数据结构

☀️详见[Redis 数据结构](http://ylzhong.top/database/2redis/3redisdatastructures.html)

### Redis 常用的数据结构有哪些？

- **5 种基础数据结构**：`String`（字符串）、`List`（列表）、`Set`（集合）、`Hash`（散列）、`Zset`（有序集合）。
- **3 种特殊数据结构**：`HyperLogLogs`（基数统计）、`Bitmap`（位存储）、`Geospatial`（地理位置）。

### String 的应用场景有哪些？

String 是 Redis 中最简单同时也是最常用的一个数据结构。`String` 是一种二进制安全的数据结构，可以用来存储任何类型的数据比如字符串、整数、浮点数、图片（图片的 base64 编码或者解码或者图片的路径）、序列化后的对象。

String 的常见应用场景如下：

- 常规数据（比如 session、token、序列化后的对象、图片的路径）的缓存；
- 计数比如用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数；
- 分布式锁（利用 `SETNX key value` 命令可以实现一个最简易的分布式锁）。

### String 还是 Hash 存储对象数据更好呢？

- `String` 存储的是**序列化后的对象数据**，存放的是整个对象。`Hash` 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合。
- `String` 存储相对来说更加节省内存，缓存相同数量的对象数据，`String` 消耗的内存约是 `Hash` 的一半。并且，存储具有多层嵌套的对象时也方便很多。如果系统对性能和资源消耗非常敏感的话，`String` 就非常适合。

### String 的底层实现是什么？

Redis 是基于 C 语言编写的，但 Redis 的 `String` 类型的底层实现并不是 C 语言中的字符串（即以空字符 `\0` 结尾的字符数组），而是自己编写了 **SDS**（Simple Dynamic String，简单动态字符串）来作为底层实现。

Redis 会根据初始化的长度决定使用哪种类型，从而减少内存的使用。

SDS 相比于 C 语言中的字符串有如下提升：

- **可以避免缓冲区溢出**：C 语言中的字符串被修改（比如拼接）时，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。SDS 被修改时，会先根据 len 属性检查空间大小是否满足要求，如果不满足，则先扩展至所需大小再进行修改操作。

- **获取字符串长度的复杂度较低**：C 语言中的字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。SDS 的长度获取直接读取 len 属性即可，时间复杂度为 O(1)。

- **减少内存分配次数**：为了避免修改（增加/减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了空间预分配和惰性空间释放两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）。

- **二进制安全**：C 语言中的字符串以空字符 `\0` 作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。SDS 使用 len 属性判断字符串是否结束，不存在这个问题。

### 购物车信息用 String 还是 Hash 存储更好呢?

由于购物车中的商品频繁修改和变动，购物车信息建议使用 `Hash` 存储：

- 用户 id 为 key；
- 商品 id 为 field，商品数量为 value。

### 使用 Redis 实现一个排行榜怎么做？

Redis 中有一个叫做 `Sorted Set` 的数据结构经常被用在各种排行榜的场景，比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、游戏中的段位排行榜、话题热度排行榜等等。

相关的一些 Redis 命令: `ZRANGE` (从小到大排序)、 `ZREVRANGE` （从大到小排序）、`ZREVRANK` (指定元素排名)。

### Set 的应用场景是什么？

Redis 中 `Set` 是一种无序集合，集合中的元素没有先后顺序但都唯一，有点类似于 Java 中的 `HashSet` 。

Set 的常见应用场景如下：

- 存放的数据不能重复的场景：网站 UV 统计（数据量巨大的场景还是 `HyperLogLog`更适合一些）、文章点赞、动态点赞等等。
- 需要获取多个数据源交集、并集和差集的场景：共同好友（交集）、共同粉丝（交集）、共同关注（交集）、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集 + 交集） 等等。
- 需要随机获取数据源中的元素的场景：抽奖系统、随机点名等等。

### 使用 Set 实现抽奖系统怎么做？

如果想要使用 `Set` 实现一个简单的抽奖系统的话，直接使用下面这几个命令就可以了：

- `SADD key member1 member2 ...`：向指定集合添加一个或多个元素。
- `SPOP key count`：随机移除并获取指定集合中一个或多个元素，适合不允许重复中奖的场景。
- `SRANDMEMBER key count`：随机获取指定集合中指定数量的元素，适合允许重复中奖的场景。

### 使用 Bitmap 统计活跃用户怎么做？

`Bitmap` 存储的是连续的二进制数字（0 和 1），通过 `Bitmap` 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。

如果想要使用 `Bitmap` 统计活跃用户的话，可以使用日期（精确到天）作为 key，然后用户 id 为 offset，如果当日活跃过就设置为 1。

![image-20230608175823735](/markdown/image-20230608175823735.png)

初始化数据：

```bash
> SETBIT 20210308 1 1
(integer) 0
> SETBIT 20210308 2 1
(integer) 0
> SETBIT 20210309 1 1
(integer) 0
```

统计 20210308~20210309 总活跃用户数:

```bash
> BITOP and desk1 20210308 20210309
(integer) 1
> BITCOUNT desk1
(integer) 1
```

统计 20210308~20210309 在线活跃用户数:

```bash
> BITOP or desk2 20210308 20210309
(integer) 1
> BITCOUNT desk2
(integer) 2
```

### 使用 HyperLogLog 统计页面 UV 怎么做？

使用 `HyperLogLog` 统计页面 UV 主要需要用到下面这两个命令：

- `PFADD key element1 element2 ...`：添加一个或多个元素到 `HyperLogLog` 中。
- `PFCOUNT key1 key2`：获取一个或者多个 `HyperLogLog` 的唯一计数。

1、将访问指定页面的每个用户 id 添加到 `HyperLogLog` 中。

```bash
PFADD PAGE_1:UV USER1 USER2 ...... USERn
```

2、统计指定页面的 UV。

```bash
PFCOUNT PAGE_1:UV
```

## Redis 持久化

 ☀️详见[Redis 持久化](http://ylzhong.top/database/2redis/4redispersistence.html)

## Redis 线程模型

::: info Redis 读写单线程

对于读写来说，Redis 一直是单线程模型。不过在 Redis 4.0 版本之后引入了多线程来执行一些大键值对的异步删除操作，Redis 6.0 之后引入了多线程来处理网络请求（提高网络IO读写性能）。

:::

### Redis 单线程了解吗？

Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，这套时间处理模型对应的是Redis中的文件事件处理器，由于文件事件处理器是单线程方式运行的，所以一般说 Redis 是单线程模型。

::: info Redis IO多路复用

文件事件处理器使用 IO 多路复用程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。

虽然文件事件处理器以单线程方式运行，但通过 IO 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对阶，这保持列 Redis 内部单线程设计的简单性。

☀️详见[IO 多路复用](https://ylzhong.top/computer/3io.html#io-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-io-multiplexing)

:::

### 单线程如何监听大量的客户端连接？

Redis 通过 IO 多路复用程序来监听来自客户端的大量连接（或者说是监听多个 socket），它将感兴趣的事件及类型注册到内核中并监听每个事件是否发生。

IO 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源消耗，（和 NIO 中的 `Selector` 组件很像）。

**文件事件处理器**包含四个部分：

- 多个 socket（客户端连接）；
- IO 多路复用程序（支持多个客户端连接的关键）；
- 文件事件派发器（将 socket 关联到相应的事件处理器）；
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）。

![image-20230609155812203](/markdown/image-20230609155812203.png)

### Redis 6.0 之前为什么不使用多线程？

**在 Redis 4.0 之后的版本中就已经加入了对多线程的支持。不过多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主线程之外的其他线程来异步处理。**

- 单线程变成容易并且易于维护；
- Redis 的性能瓶颈不再 CPU，主要在于内存和网络；
- 多线程就会存在死锁、线程上下文切换等问题，可能会影响性能。

### Redis 6.0 之后为何引入了多线程？

Redis 6.0 引入多线程主要是为了提高网络IO读写性能，这是 Redis 中的一个性能瓶颈。

虽然引入了多线程，但是 Redis 的多线程只是在网络数据的读写上使用，执行命令仍然是单线程顺序执行。

### Redis后台线程了解吗？

虽然经常说 Redis 是单线程模型（主要逻辑是单线程完成的），但实际还有一些后台线程用于执行一些比较耗时的操作：

- 通过 `bio_close_file` 后台线程来释放 AOF/RDB 等过程中产生的临时文件资源。
- 通过 `bio_aof_fsync` 后台线程调用 `fsync` 函数将系统内核缓冲区还未同步到到磁盘的数据强制刷到磁盘（ AOF 文件）。
- 通过 `bio_lazy_free` 后台线程释放大对象（已删除）占用的内存空间.

## Redis 内存管理

### Redis 给缓存数据设置过期时间有啥用？

因为内存有限，不设置过期时间，会导致 OOM。

Redis 自带了给缓存数据设置过期时间的功能，比如：



```bash
127.0.0.1:6379> expire key 60 # 数据在 60s 后过期
(integer) 1
127.0.0.1:6379> setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)
OK
127.0.0.1:6379> ttl key # 查看数据还有多久过期
(integer) 56
```

Redis 中除了字符串类型有自己独有设置过期时间的命令 `setex` 外，其他方法都需要依靠 `expire` 命令来设置过期时间。 `persist` 命令可以溢出一个键的过期时间。

### Redis 是如何判断数据是否过期的？

Redis 通过过期字典（可以看做是 hash 表）来保存数据过期的时间，过期字典的键指向 Redis 数据库中的某个 key，过期字典的值是一个 `long long` 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间。

### 过期数据的删除策略

常用的过期数据的删除策略就两个：

1. **惰性删除**：只会在取出 key 的时候才对数据进行过期检查，这样对 CPU 友好，但是可能会造成过多的 key 没有被删除。
2. **定期删除**：每隔一段时间抽取一批 key 执行删除过期 key 操作。并且 Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。

### Redis 内存淘汰机制

Redis 提供 6 种数据淘汰策略：

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（`server.db[i].expires`）中挑选最近最少使用的数据淘汰。
2. **volatile-ttl**：从已设置过期时间的数据集（`server.db[i].expires`）中挑选将要过期的数据淘汰。
3. **volatile-random**：从已设置过期时间的数据集（`server.db[i].expires`）中任意选择数据淘汰。
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。
5. **allkeys-random**：从数据集（`server.db[i].dict`）中任意选择数据淘汰。
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。

4.0 版本后增加以下两种：

1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集（`server.db[i].expires`）中挑选最不经常使用的数据淘汰。
2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。
